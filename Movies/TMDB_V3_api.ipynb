{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48d9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmdbv3api import TMDb, Movie, Discover, TV, Person, Season\n",
    "from tmdbv3api import Account\n",
    "from tmdbv3api import Authentication\n",
    "\n",
    "##Import the rest of required libraries\n",
    "import time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set(palette='icefire') # set the default Seaborn style for graphics\n",
    "\n",
    "## Own functions\n",
    "import functions_1115 as func\n",
    "\n",
    "##TMDB details\n",
    "##Account details for getting movie reccomendations\n",
    "##Run this block only once during a session\n",
    "tmdb = TMDb()\n",
    "tmdb.api_key = '0921b0cce35c0b2ec8b874614d1d0b47' ##insert apikey\n",
    "tmdb.language = 'en'\n",
    "\n",
    "USERNAME = \"cybercat94\"\n",
    "PASSWORD = \"Wave1994@\"\n",
    "auth = Authentication(username=USERNAME, password=PASSWORD)\n",
    "account = Account()\n",
    "details = account.details()\n",
    "movie = Movie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778af64a",
   "metadata": {},
   "source": [
    "# List of functions\n",
    "#### 1. `Full_Mov_DB_2_CSV(date)`\n",
    "    TMDB provides daily exports of its entire database.\n",
    "    However, there are not many attributes to this list.\n",
    "    Takes a date param as string (YYYY-MM-DD), and writes the export for that day to a CSV file in the local folder.\n",
    "#### 2. `consec_dict_2_df(dictionary_in)`\n",
    "    Converts a dictionary in the style of a DF into a Pandas Dataframe.\n",
    "    E.g. each column has multiple rows containing the information for an index.\n",
    "    **still a work in progress**\n",
    "#### 3. `financialstat_counter(data)`\n",
    "    Sends API requests by passing a list of movie IDs\n",
    "    Running tally of the number of API calls\n",
    "    Shows number of successful and unsuccessful API calls after executing\n",
    "#### 4. `discover_2_csv(dict_param, output)`\n",
    "    Searches TMDB database based on given search parameters\n",
    "    Returns a maximum of 500*20 movie entries (10000)\n",
    "    Exports the dataframe to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004f5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract daily exports of entire TMBD database\n",
    "## Function accepts ISO 8601 spec for dates\n",
    "## e.g. Full_Mov_DB_2_CSV('YYYY-MM-DD')\n",
    "def full_mov_db_2_csv(date):\n",
    "    ## format the fetch url\n",
    "    db_online_path='http://files.tmdb.org/p/exports/movie_ids_'+date[5:7]+'_'+date[8:10]+'_'+date[:4]+'.json.gz'\n",
    "    print(\"Export link:\", db_online_path)\n",
    "    \n",
    "    ## will throw exception if url does not exist\n",
    "    try:\n",
    "        data_raw = pd.read_json(db_online_path, compression='gzip', lines=True)\n",
    "        print(\"Writing to file...\")\n",
    "    except:\n",
    "        print('Error in extracting file from link...\\nFile may not yet exist on TMDB.')\n",
    "        return\n",
    "    \n",
    "    ## format the local file name\n",
    "    db_path='FullDB_'+date+'.csv'\n",
    "    data_raw.to_csv(db_path)\n",
    "    print(\"Exported to local folder:\",db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec504e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input param must be a list/array containing multiple dictionaries that have identically formatted keys\n",
    "## Returns a propery formatted dataframe with the keys at column positions\n",
    "def consec_dict_2_df(dict_in):\n",
    "    return_df = None\n",
    "    for item in dict_in:\n",
    "        sub_df = pd.DataFrame.from_dict(item, orient='index')\n",
    "        if return_df is None:\n",
    "            return_df = sub_df.T\n",
    "        else:\n",
    "            return_df = pd.concat([return_df,sub_df.T], sort=True)\n",
    "    ## reindex dataframe, auto-convert to most suitable datatype\n",
    "    return return_df.convert_dtypes().reset_index(drop=True)\n",
    "\n",
    "## testing\n",
    "#consec_dict_2_df(stats['casts']['crew'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pass the 'id' column from daily export CSV into function\n",
    "## take the first 10 values and increment by an order of magnitude for each iteration\n",
    "\n",
    "def financialstat_counter(data):\n",
    "    hit=0\n",
    "    total_count=0\n",
    "    total_uncount=0\n",
    "    top=len(data)\n",
    "\n",
    "    for item_id in data:\n",
    "        ## visual indication of progress\n",
    "        time.sleep(0.001)\n",
    "        if total_count+total_uncount == top-1:\n",
    "            print('API call complete:   '+str(total_count+total_uncount+1)+'/'+str(top))\n",
    "        else:\n",
    "            print('API calls: '+str(total_count+total_uncount+1)+'/'+str(top),end = \"\\r\")\n",
    "\n",
    "        ## skips call if api barfs \n",
    "        try:\n",
    "            mov = movie.details(item_id)\n",
    "            if(mov['budget'] and mov['revenue']):\n",
    "                hit += 1\n",
    "            total_count += 1\n",
    "        except:\n",
    "            total_uncount += 1\n",
    "    \n",
    "    value=hit/total_count*100\n",
    "    print(\"Successful calls:   \",str(total_count))\n",
    "    print(\"Unsuccessful calls: \",str(total_uncount))\n",
    "    print(\"Percentage of movies with financial statistics: \",str(value)+'%\\n')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb59ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    ## Comment out params that are not required for search\n",
    "    'sort_by':'',\n",
    "    ## 'popularity.asc/desc','release_date.asc/desc','revenue.asc/desc','original_tite.asc/desc'\n",
    "    \n",
    "    'page':'1', ## 1-500, default 1. Do not modify this parameter.\n",
    "    'primary_release_year':'', ## YYYY\n",
    "    'primary_release_date.gte':'', ## 'YYYY-MM-DD'\n",
    "    'primary_release_date.lte':'', ## 'YYYY-MM-DD'\n",
    "    'release_date.gte':'', ## 'YYYY-MM-DD'\n",
    "    'release_date.lte':'', ## 'YYYY-MM-DD'\n",
    "    'year':'', ## YYYY\n",
    "    \n",
    "    ## Comma-separated list of person IDs\n",
    "    'with_cast':'',\n",
    "    'with_crew':'',\n",
    "    'with_people':'',\n",
    "    ## Comma-separated list of company IDs\n",
    "    'with_companies':'',\n",
    "    ## Comma-separated list of genre IDs\n",
    "    'with_genres':'',\n",
    "    'without_genres':'',\n",
    "    ## Comma-separated list of keyword IDs\n",
    "    'with_keywords':'',\n",
    "    \n",
    "    ## Integer minutes\n",
    "    'with_runtime.gte':'',\n",
    "    'with_runtime.lte':''  \n",
    "}\n",
    "\n",
    "def discover_2_csv(dict_param, output):\n",
    "    df_out = None\n",
    "    call_fail = 0\n",
    "    \n",
    "    ## Input validation\n",
    "    if type(dict_param)!=dict or type(output)!=str:\n",
    "        print('Error, inputs must be a dictionary and a string')\n",
    "        return\n",
    "    \n",
    "    ## up to 500 pages available to extract, depending on how broad search is. So up to 20*500=10000 movies possible\n",
    "    for page_no in range(1,501): ## for debugging purposes, change to max=10\n",
    "        \n",
    "        ## Set the current page\n",
    "        dict_param['page']=page_no\n",
    "        \n",
    "        ## Get the list\n",
    "        movie_list = discover.discover_movies(dict_param)\n",
    "        \n",
    "        ## Terminate search if most recent page has nothing\n",
    "        if len(movie_list) == 0:\n",
    "            break\n",
    "            \n",
    "        ## Make the large dataframe\n",
    "        try:\n",
    "            if df_out is None:\n",
    "                df_out = func.consec_dict_2_df(movie_list)\n",
    "            else:\n",
    "                df_out = pd.concat([df_out,func.consec_dict_2_df(movie_list)],sort=True)\n",
    "        except:\n",
    "            call_fail += 1\n",
    "        \n",
    "        ## Output statements to keep track of things\n",
    "        print('Page number: '+str(page_no)+'/500', end='\\r')\n",
    "    \n",
    "    ## Resetting the index to count normally\n",
    "    df_out.reset_index(drop=True, inplace=True)\n",
    "    print('\\nSearch complete\\n'+str(page_no*20)+' movies found')\n",
    "    print(str(len(df_out))+' movies returned')\n",
    "    print(str(call_fail)+' calls did not get through')\n",
    "    df_out.to_csv(output)\n",
    "    print(\"Exported to local folder:\",output)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14179d32",
   "metadata": {},
   "source": [
    "# Cleaning up the dataset \n",
    "#### Remove entries that are:\n",
    "- movies release before 2000 (21st century movies in dataset)\n",
    "- movies with no financial information (0 box office and 0 budget)\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ebbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create local CSV file\n",
    "## hashed out this one as local fil for 2021-03-15 has already been created\n",
    "#### full_mov_db_2_csv('2021-03-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('FullDB_2021-03-15.csv')\n",
    "display(data_raw.describe())\n",
    "display(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking a look at what col headers are present in movie details\n",
    "stats = movie.details(10000)\n",
    "print(pd.DataFrame(stats),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking a peek at a movie's stats\n",
    "## does NOT use IMDB id, uses 'id' <- not sure about where this id comes from\n",
    "## taking a random movie id\n",
    "stats = movie.details(805900)\n",
    "movie_attributes = ['title','original_title','id','imdb_id','release_date','genres','budget','revenue','overview','popularity','spoken_languages','vote_average','production_companies','production_countries']\n",
    "for stuff in movie_attributes:\n",
    "    print(stuff,':',stats[stuff])\n",
    "## the 'casts' key contains too many items, using the next code box to look at casts\n",
    "## production countries may also have many elements for large movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa13cd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## looking at actors in a specific movie\n",
    "cast_attributes = ['original_name','gender','popularity','adult']\n",
    "for thing in stats['casts']['cast']:\n",
    "    for item in cast_attributes:\n",
    "        print(item,':',thing[item])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "##looking at crew members in a specific movie\n",
    "crew_attributes = ['original_name','id','gender','adult', 'job','department','known_for_department']\n",
    "cast_count = len(stats['casts']['crew'])\n",
    "print('Number of cast members:', str(cast_count),'\\n')\n",
    "for item in stats['casts']['crew']:\n",
    "    for subitem in crew_attributes:\n",
    "        print(subitem,':',item[subitem])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d640088",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame.from_dict(stats['casts']['crew'][0], orient='index')\n",
    "#print(test_df,'\\n')\n",
    "#test_df.info()\n",
    "\n",
    "## Test code, still unfinished\n",
    "## Dictionary to DF process:\n",
    "## Extract dictionary, place into DataFrame\n",
    "## Concatenate consec dictionaries together\n",
    "## Recast columns into the appropriate data types\n",
    "new_df = None\n",
    "for item in stats['casts']['crew']:\n",
    "    sub_df = pd.DataFrame.from_dict(item, orient='index')\n",
    "    if new_df is None:\n",
    "        new_df = sub_df.T\n",
    "    else:\n",
    "        new_df = pd.concat([new_df, sub_df.T], sort=True)\n",
    "new_df = new_df.convert_dtypes().reset_index()\n",
    "new_df.info()\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "## shortening the dataframe size so that code does not take forever to run\n",
    "## 10K entries is apparently too long\n",
    "## limit to 100 entries for now\n",
    "data_short = data_raw.head(10)\n",
    "data_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking the number of movies with financial data\n",
    "## only counts movies that have both budget and box office numbers (not zero)\n",
    "## Looks like the call rate is heavily limited after approximately 5000 calls\n",
    "## API calls after 6000 are reduced to around 4 per second\n",
    "## Call API in batches of 5000 or less to get past this bottleneck\n",
    "## Need to check the off time in between batches\n",
    "\n",
    "hit=0\n",
    "total_count=0\n",
    "total_uncount=0\n",
    "top=len(data_short['id'])\n",
    "\n",
    "for item_id in data_short['id']:\n",
    "    ## visual indication of progress\n",
    "    time.sleep(0.001)\n",
    "    if total_count+total_uncount == top-1:\n",
    "        print('API call complete:   '+str(total_count+total_uncount+1)+'/'+str(top))\n",
    "    else:\n",
    "        print('API calls: '+str(total_count+total_uncount+1)+'/'+str(top),end = \"\\r\")\n",
    "    \n",
    "    ## skips call if api barfs \n",
    "    try:\n",
    "        mov = movie.details(item_id)\n",
    "        if(mov['budget'] and mov['revenue']):\n",
    "            hit += 1\n",
    "        total_count += 1\n",
    "    except:\n",
    "        total_uncount += 1\n",
    "        \n",
    "print(\"Successful calls:   \",str(total_count))\n",
    "print(\"Unsuccessful calls: \",str(total_uncount))\n",
    "print(\"Percentage of movies with financial statistics: \",str(hit/total_count*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad17439",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "## must be placed at the TOP of the cell, including above comments\n",
    "## Checking api call rate/success rate\n",
    "## Takes the list of movie IDs and samples a set numeber of them randomly\n",
    "rep_list = [1,10,100]\n",
    "count=0\n",
    "x=[]\n",
    "for rep in rep_list:\n",
    "    x.append(0.01 * financialstat_counter(random.sample(list(data_raw['id']),rep) ) )\n",
    "    count+=1\n",
    "    if count == len(rep_list):\n",
    "        break\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
